# Backend API Contract Documentation

## Overview
This document outlines the complete API contract that the backend needs to implement for the DeepTalk AI Interviews application. The frontend is configured to connect to the backend via environment variables.

## Environment Variables

Create a `.env` file in the frontend root:

```env
VITE_API_BASE_URL=http://localhost:8000
VITE_WS_BASE_URL=ws://localhost:8000
```

---

## API Endpoints

### 1. Start Interview

**Endpoint:** `POST /api/interviews/start`

**Description:** Initiates a new AI interview session based on the provided persona.

**Request Headers:**
```http
Content-Type: application/json
```

**Request Body:**
```json
{
  "persona": {
    "name": "Sarah Chen",
    "role": "Startup Founder",
    "industry": "B2B SaaS",
    "background": "Building a project management tool for remote teams. Frustrated with existing solutions that are either too complex or too simple. Looking for a balanced solution that works for both technical and non-technical team members."
  }
}
```

**Success Response (201 Created):**
```json
{
  "interviewId": "550e8400-e29b-41d4-a716-446655440000",
  "status": "in-progress"
}
```

**Error Responses:**

400 Bad Request:
```json
{
  "error": "Invalid persona data",
  "message": "All persona fields (name, role, industry, background) are required"
}
```

500 Internal Server Error:
```json
{
  "error": "Failed to start interview",
  "message": "Internal server error message"
}
```

**Backend Implementation Notes:**
- Generate a unique `interviewId` (UUID recommended)
- Store the persona information in your database
- Initiate the AI interview process (this may be asynchronous)
- Return immediately with the interviewId
- Start generating interview messages in the background

---

### 2. WebSocket Stream - Interview Messages

**Endpoint:** `WS /api/interviews/{interviewId}/stream`

**Description:** Real-time WebSocket connection that streams interview messages as they are generated by AI agents.

**Connection URL:**
```
ws://localhost:8000/api/interviews/550e8400-e29b-41d4-a716-446655440000/stream
```

**Message Types:**

#### Message Type: `message`
Sent when a new chat message is generated (interviewer or customer).

```json
{
  "type": "message",
  "payload": {
    "id": "msg-001",
    "agent": "interviewer",
    "message": "Hi! Thanks for taking the time to chat with me today. I'd love to learn more about your experience. Can you start by telling me a bit about what you do?",
    "timestamp": "2025-10-20T10:30:15.000Z"
  }
}
```

**Fields:**
- `id` (string): Unique message identifier
- `agent` (string): Either `"interviewer"` or `"customer"`
- `message` (string): The message content
- `timestamp` (string): ISO 8601 timestamp

#### Message Type: `complete`
Sent when the interview is finished.

```json
{
  "type": "complete",
  "payload": {
    "interviewId": "550e8400-e29b-41d4-a716-446655440000",
    "messageCount": 15,
    "completedAt": "2025-10-20T10:45:30.000Z"
  }
}
```

#### Message Type: `error`
Sent when an error occurs during the interview.

```json
{
  "type": "error",
  "error": "AI service unavailable",
  "message": "Failed to generate next response"
}
```

**WebSocket Connection Lifecycle:**

1. **Client connects** â†’ Backend validates interviewId
2. **Backend streams messages** â†’ Send `message` type for each Q&A
3. **Interview completes** â†’ Send `complete` type, then close connection
4. **On error** â†’ Send `error` type, then close connection

**Backend Implementation Notes:**
- Validate the interviewId exists before accepting the connection
- Stream messages as they are generated by your AI agents
- Typical interview has 10-20 messages (5-10 Q&A pairs)
- Send messages with realistic delays (1-3 seconds between messages)
- Close the WebSocket connection after sending `complete` or `error`
- Handle client disconnections gracefully

**Message Timing Example:**
```
0:00 - Connection established
0:02 - Message 1 (interviewer)
0:05 - Message 2 (customer)
0:08 - Message 3 (interviewer)
0:12 - Message 4 (customer)
...
2:30 - Message 15 (interviewer)
2:32 - Complete event
2:32 - Connection closed
```

---

### 3. Get Interview Status

**Endpoint:** `GET /api/interviews/{interviewId}/status`

**Description:** Retrieves the current status of an interview session.

**Request:**
```http
GET /api/interviews/550e8400-e29b-41d4-a716-446655440000/status
```

**Success Response (200 OK):**
```json
{
  "interviewId": "550e8400-e29b-41d4-a716-446655440000",
  "status": "completed",
  "messageCount": 15,
  "isComplete": true,
  "createdAt": "2025-10-20T10:30:00.000Z",
  "completedAt": "2025-10-20T10:45:30.000Z"
}
```

**Status Values:**
- `"in-progress"` - Interview is currently active
- `"completed"` - Interview has finished successfully
- `"failed"` - Interview encountered an error

**Error Responses:**

404 Not Found:
```json
{
  "error": "Interview not found",
  "message": "No interview found with ID: 550e8400-e29b-41d4-a716-446655440000"
}
```

---

### 4. Get Interview Insights

**Endpoint:** `GET /api/interviews/{interviewId}/insights`

**Description:** Retrieves AI-generated insights after the interview is completed.

**Request:**
```http
GET /api/interviews/550e8400-e29b-41d4-a716-446655440000/insights
```

**Success Response (200 OK):**
```json
{
  "summary": "This founder struggles to find the right balance between powerful features and simplicity in project management tools. The conversation reveals deep frustration with tool fragmentation and a vision for universal clarity across teams.",
  "overallMood": "Frustrated but Hopeful",
  "moodEmoji": "ðŸ˜¤â†’ðŸ˜Œ",
  "topicCloud": [
    "complexity",
    "simplicity",
    "fragmentation",
    "clarity",
    "onboarding",
    "technical teams",
    "integration",
    "workflow",
    "status",
    "training"
  ],
  "themes": [
    {
      "theme": "Tool Complexity vs Simplicity",
      "quotes": [
        "Too complex or too simple, never just right",
        "Powerful enough for engineering but simple enough for marketing"
      ],
      "emotionalTone": "Frustration",
      "underlyingNeed": "Balance & Flexibility"
    },
    {
      "theme": "Team Fragmentation",
      "quotes": [
        "Developers using one tool, designers using another",
        "Nothing synced, lots of duplicate work"
      ],
      "emotionalTone": "Overwhelm",
      "underlyingNeed": "Unity & Synchronization"
    },
    {
      "theme": "Onboarding Friction",
      "quotes": [
        "Within 5 minutes they understand how to create a task",
        "No documentation needed"
      ],
      "emotionalTone": "Determination",
      "underlyingNeed": "Ease of Use"
    }
  ],
  "humanInsights": {
    "coreDesires": [
      "Belonging â€” wants all team members to feel the tool is built for them",
      "Control â€” seeks to eliminate chaos and create predictable workflows",
      "Recognition â€” desires to build something that solves a real problem elegantly"
    ],
    "fearsOrFrustrations": [
      "Fear of building yet another tool that doesn't quite work",
      "Frustration with existing solutions that force unnecessary trade-offs",
      "Worry about team members feeling excluded or overwhelmed by tools"
    ],
    "aspirations": [
      "Wants to create universal clarity that everyone can understand",
      "Aspires to eliminate the need for training and documentation",
      "Dreams of bridging technical and non-technical worlds seamlessly"
    ]
  },
  "contextualInsights": {
    "whenProblemFelt": [
      "When teams went remote and tool fragmentation became visible",
      "During onboarding when new members struggle with complex interfaces",
      "In daily standups when status updates are scattered across platforms"
    ],
    "triggersMoments": [
      "Personal frustration with existing tools led to building a solution",
      "Seeing non-technical team members give up on powerful tools",
      "Watching developers create workarounds due to tool limitations"
    ],
    "preventionBarriers": [
      "Existing tools force a choice between simplicity and power",
      "Integration complexity makes unified solutions difficult",
      "Training overhead prevents quick adoption of sophisticated tools"
    ]
  },
  "opportunityMap": [
    "People are overwhelmed by feature complexity â€” explore progressive disclosure patterns",
    "Team fragmentation is causing real workflow pain â€” consider unified but flexible interfaces",
    "Onboarding friction is a major barrier â€” investigate zero-training interaction models",
    "Status visibility is a universal need â€” explore ambient awareness systems",
    "Role-based needs are conflicting â€” research adaptive UI that serves multiple user types"
  ],
  "emotionalJourney": [
    {
      "phase": "Opening",
      "emotion": "Engaged Curiosity",
      "emoji": "ðŸ¤”"
    },
    {
      "phase": "Problem Discovery",
      "emotion": "Rising Frustration",
      "emoji": "ðŸ˜¤"
    },
    {
      "phase": "Deep Dive",
      "emotion": "Passionate Explanation",
      "emoji": "ðŸ’¡"
    },
    {
      "phase": "Vision Sharing",
      "emotion": "Hopeful Determination",
      "emoji": "ðŸ˜Œ"
    },
    {
      "phase": "Closure",
      "emotion": "Satisfied Reflection",
      "emoji": "âœ¨"
    }
  ]
}
```

**Error Responses:**

404 Not Found:
```json
{
  "error": "Interview not found",
  "message": "No interview found with ID: 550e8400-e29b-41d4-a716-446655440000"
}
```

400 Bad Request (if interview not completed):
```json
{
  "error": "Interview not completed",
  "message": "Insights are only available after the interview is completed"
}
```

**Backend Implementation Notes:**
- This endpoint should only return data after the interview is `completed`
- Use AI/LLM to analyze the full conversation and extract:
  - Overall themes and patterns
  - Emotional tone analysis
  - Direct quotes from the conversation
  - Human psychology insights (desires, fears, aspirations)
  - Contextual understanding (when/why problems occur)
  - Actionable opportunities for product development
  - Emotional journey throughout the conversation
- Cache the insights after generation to avoid regenerating on each request

---

## Data Models

### Persona
```typescript
interface Persona {
  name: string;          // Customer name
  role: string;          // Job title/role
  industry: string;      // Industry/domain
  background: string;    // Detailed background context
}
```

### ChatMessage
```typescript
interface ChatMessage {
  id: string;                           // Unique message ID
  agent: 'interviewer' | 'customer';    // Who sent the message
  message: string;                      // Message content
  timestamp: Date;                      // When message was sent (ISO 8601)
}
```

### ThemeInsight
```typescript
interface ThemeInsight {
  theme: string;              // Theme name
  quotes: string[];           // Direct quotes from interview
  emotionalTone: string;      // Emotional tone (e.g., "Frustration")
  underlyingNeed: string;     // Core need behind the theme
}
```

### HumanInsight
```typescript
interface HumanInsight {
  coreDesires: string[];           // Core psychological desires
  fearsOrFrustrations: string[];   // Fears and frustrations
  aspirations: string[];           // Aspirations and goals
}
```

### ContextualInsight
```typescript
interface ContextualInsight {
  whenProblemFelt: string[];      // When the problem is experienced
  triggersMoments: string[];      // What triggers the problem
  preventionBarriers: string[];   // What prevents solving it
}
```

### EmotionalPhase
```typescript
interface EmotionalPhase {
  phase: string;        // Phase name (e.g., "Opening")
  emotion: string;      // Emotion description
  emoji: string;        // Emoji representation
}
```

### Insights
```typescript
interface Insights {
  summary: string;                          // Overall summary
  overallMood: string;                      // Overall mood description
  moodEmoji: string;                        // Emoji representing mood
  topicCloud: string[];                     // Key topics discussed
  themes: ThemeInsight[];                   // Identified themes
  humanInsights: HumanInsight;              // Human psychology layer
  contextualInsights: ContextualInsight;    // Contextual understanding
  opportunityMap: string[];                 // Actionable opportunities
  emotionalJourney: EmotionalPhase[];       // Emotional arc of interview
}
```

---

## Implementation Flow

### Complete User Journey

1. **User fills persona form** (`/new-interview`)
   - Frontend validates all fields
   - Calls `POST /api/interviews/start`
   - Backend generates interviewId and returns it
   - Frontend stores interviewId in sessionStorage
   - Frontend redirects to `/interview`

2. **Interview streaming** (`/interview`)
   - Frontend connects to WebSocket: `ws://host/api/interviews/{interviewId}/stream`
   - Backend streams messages one by one
   - Frontend displays messages in real-time
   - Backend sends `complete` message when done
   - Frontend shows "View Insights" button

3. **View insights** (`/insights`)
   - Frontend calls `GET /api/interviews/{interviewId}/insights`
   - Backend returns pre-generated insights
   - Frontend displays insights in multiple tabs

---

## WebSocket Implementation Example (Backend Pseudocode)

```python
# Example in Python with WebSockets
async def interview_stream(websocket, interview_id):
    # Validate interview exists
    interview = get_interview(interview_id)
    if not interview:
        await websocket.close(code=4004, reason="Interview not found")
        return

    try:
        # Generate interview messages using AI
        messages = await generate_interview_messages(interview.persona)

        # Stream each message
        for message in messages:
            await websocket.send_json({
                "type": "message",
                "payload": {
                    "id": message.id,
                    "agent": message.agent,
                    "message": message.content,
                    "timestamp": message.timestamp.isoformat()
                }
            })

            # Realistic delay between messages
            await asyncio.sleep(random.uniform(1.5, 3.0))

        # Send completion
        await websocket.send_json({
            "type": "complete",
            "payload": {
                "interviewId": interview_id,
                "messageCount": len(messages),
                "completedAt": datetime.now().isoformat()
            }
        })

        # Mark interview as completed in database
        mark_interview_completed(interview_id)

        # Generate insights in background (async)
        asyncio.create_task(generate_insights(interview_id, messages))

        await websocket.close()

    except Exception as e:
        await websocket.send_json({
            "type": "error",
            "error": str(e),
            "message": "Failed to generate interview"
        })
        await websocket.close()
```

---

## AI/LLM Integration Guidelines

### Interview Generation
Your backend should use an LLM to:
1. Take the persona as input
2. Generate a natural interview conversation (10-20 messages)
3. Have the "interviewer" agent ask deep, insightful questions
4. Have the "customer" agent respond based on the persona background
5. Follow good interview techniques:
   - Ask open-ended questions
   - Dig deeper into motivations
   - Explore emotional context
   - Uncover underlying needs
   - Use "why" and "how" questions

### Insights Generation
After the interview, use an LLM to:
1. Analyze the full conversation
2. Extract themes and patterns
3. Identify direct quotes that support each theme
4. Understand emotional tone and journey
5. Derive human psychology insights
6. Map opportunities for product development
7. Create a topic cloud of key terms

**Recommended Prompt Structure:**
```
Analyze this customer interview and provide:
1. Overall summary
2. Key themes with supporting quotes
3. Emotional tone analysis
4. Human desires, fears, and aspirations
5. Contextual insights (when/why/what prevents)
6. Opportunity map for product development
7. Emotional journey through the conversation

Interview:
[Full interview transcript]
```

---

## CORS Configuration

Your backend must enable CORS for the frontend origin:

```python
# Example CORS headers
Access-Control-Allow-Origin: http://localhost:5173
Access-Control-Allow-Methods: GET, POST, OPTIONS
Access-Control-Allow-Headers: Content-Type
Access-Control-Allow-Credentials: true
```

---

## Testing

### Manual Testing with curl

**Start Interview:**
```bash
curl -X POST http://localhost:8000/api/interviews/start \
  -H "Content-Type: application/json" \
  -d '{
    "persona": {
      "name": "Test User",
      "role": "Developer",
      "industry": "Tech",
      "background": "Testing the API"
    }
  }'
```

**Get Status:**
```bash
curl http://localhost:8000/api/interviews/{interviewId}/status
```

**Get Insights:**
```bash
curl http://localhost:8000/api/interviews/{interviewId}/insights
```

### WebSocket Testing

Use a WebSocket client like `wscat`:
```bash
npm install -g wscat
wscat -c ws://localhost:8000/api/interviews/{interviewId}/stream
```

---

## Error Handling

All API errors should follow this format:

```json
{
  "error": "Error type",
  "message": "Detailed error message"
}
```

Common HTTP status codes:
- `200 OK` - Success
- `201 Created` - Resource created
- `400 Bad Request` - Invalid input
- `404 Not Found` - Resource not found
- `500 Internal Server Error` - Server error

WebSocket close codes:
- `1000` - Normal closure
- `4004` - Interview not found
- `4500` - Internal server error

---

## Performance Considerations

1. **Interview Generation**: Should start within 1-2 seconds
2. **Message Streaming**: 1-3 second delay between messages
3. **Insights Generation**: Can take 5-10 seconds (generate asynchronously)
4. **WebSocket Connections**: Support at least 100 concurrent connections
5. **Database**: Index on `interviewId` for fast lookups

---

## Security Considerations

1. **Validate all inputs** - Sanitize persona data
2. **Rate limiting** - Prevent abuse of interview generation
3. **Authentication** (optional) - Add JWT if needed in future
4. **Input size limits** - Limit persona background to reasonable length (e.g., 2000 chars)
5. **WebSocket auth** - Validate interviewId exists before streaming
6. **CORS** - Only allow your frontend origin

---

## Database Schema Suggestion

```sql
-- Interviews table
CREATE TABLE interviews (
  id UUID PRIMARY KEY,
  persona_name VARCHAR(255) NOT NULL,
  persona_role VARCHAR(255) NOT NULL,
  persona_industry VARCHAR(255) NOT NULL,
  persona_background TEXT NOT NULL,
  status VARCHAR(20) NOT NULL, -- 'in-progress', 'completed', 'failed'
  created_at TIMESTAMP DEFAULT NOW(),
  completed_at TIMESTAMP,
  message_count INTEGER DEFAULT 0
);

-- Messages table
CREATE TABLE messages (
  id UUID PRIMARY KEY,
  interview_id UUID REFERENCES interviews(id),
  agent VARCHAR(20) NOT NULL, -- 'interviewer' or 'customer'
  message TEXT NOT NULL,
  timestamp TIMESTAMP DEFAULT NOW()
);

-- Insights table (store as JSONB)
CREATE TABLE insights (
  id UUID PRIMARY KEY,
  interview_id UUID UNIQUE REFERENCES interviews(id),
  data JSONB NOT NULL,
  created_at TIMESTAMP DEFAULT NOW()
);
```

---

## Summary

This backend needs to implement:
1. âœ… REST endpoint to start interviews
2. âœ… WebSocket endpoint to stream interview messages
3. âœ… REST endpoint to get interview status
4. âœ… REST endpoint to get insights
5. âœ… AI/LLM integration for interview generation
6. âœ… AI/LLM integration for insights analysis

The frontend is fully implemented and ready to connect to your backend once these endpoints are available.
